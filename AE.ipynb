{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from keras.datasets import fashion_mnist\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initializing device details and Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "(xTrain, yTrain), (xTest, yTest) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length, breadth = xTrain[0].shape\n",
    "flattenDim = length * breadth\n",
    "#xTrain = torch.FloatTensor(np.round(xTrain / 27).astype(int)).to(device)\n",
    "xTrain = np.round(xTrain / 27).astype(int)\n",
    "xTest = np.round(xTest / 27).astype(int)\n",
    "xTrainFlat = torch.FloatTensor(np.reshape(xTrain, (-1,flattenDim))).to(device)\n",
    "xTestFlat = np.reshape(xTest, (-1,flattenDim)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Displaying sample images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImages(imageList, rows, columns):\n",
    "    fig, grid = plt.subplots(rows,columns) \n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            grid[i,j].axis('off')\n",
    "            grid[i,j].imshow(np.reshape(imageList[(i-1)*rows+j], (28,28)))\n",
    "\n",
    "numSamples = 8\n",
    "randomIndices = random.sample(range(0, len(xTrain)), numSamples)\n",
    "displayImages(list(np.array(xTrain)[randomIndices]), 2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initializing TrainLoader and TestLoader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(dataset = xTrainFlat, batch_size = 32, shuffle = True)\n",
    "testLoader = DataLoader(dataset = xTestFlat, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Defining AutoEncoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "        nn.Linear(in_features = 784, out_features = 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features = 512, out_features = 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features = 256, out_features = 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features = 128, out_features = 64),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "        nn.Linear(in_features = 64, out_features = 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features = 128, out_features = 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features = 256, out_features = 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features = 512, out_features = 784),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latentRepresentation = self.Encoder(x)\n",
    "        decoderOutput = self.Decoder(latentRepresentation)\n",
    "        return latentRepresentation, decoderOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training the AutoEncoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeModel = autoencoder().to(device)\n",
    "modelParameters = list(aeModel.parameters())\n",
    "criterion = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.SGD(modelParameters, lr = (1e-2), momentum = 0.7)\n",
    "\n",
    "epochLoss = []\n",
    "epochList = np.arange(0, 100, dtype = int)\n",
    "\n",
    "encoderOutputs = []\n",
    "decoderOutputs = []\n",
    "for epoch in range(100):\n",
    "  losses = []\n",
    "  for batchIndex, batchImage in enumerate(trainLoader):\n",
    "    batchImage = batchImage.to(device)\n",
    "    batchImage = batchImage.unsqueeze(1)\n",
    "    batchLatent, reconstructedImage = aeModel(batchImage)\n",
    "    loss = criterion(reconstructedImage, batchImage)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.cpu().detach().numpy())\n",
    "  print(\"Epoch: \",epoch,\"| Average loss: \",np.round(np.average(losses), 3),\"| Lowest Loss: \",np.round(np.amin(losses), 3))\n",
    "  epochLoss.append(np.round(np.amin(losses), 3))\n",
    "  torch.save(aeModel.state_dict(), \"AE.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plotting graph of loss versus epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochList, epochLoss, color = 'blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Lowest loss per epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluating reconstruction capabilities on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples = 5\n",
    "randomIndices = random.sample(range(0, len(xTest)), numSamples)\n",
    "testSamples = list(np.array(xTest)[randomIndices])\n",
    "latentOutputs = []\n",
    "reconstructedOutputs = []\n",
    "displayList = []\n",
    "\n",
    "aeModel.eval()\n",
    "for testImage in testSamples:\n",
    "    encodedOutput, decodedOutput = aeModel(torch.FloatTensor(np.reshape(testImage, (-1,flattenDim))).to(device))\n",
    "    latentOutputs.append(encodedOutput.cpu().detach().numpy().reshape(8, 8))\n",
    "    reconstructedOutputs.append(decodedOutput.cpu().detach().numpy().reshape(28, 28))\n",
    "    displayList.append(testImage)\n",
    "    displayList.append(decodedOutput.cpu().detach().numpy().reshape(28, 28))\n",
    "\n",
    "displayList = testSamples + reconstructedOutputs\n",
    "\n",
    "displayImages(displayList, 2, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dce92b59414b6f3d3d2d8fa4cc50c6a1297a8b6cc151ffcfeb96fc9a7b723860"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
