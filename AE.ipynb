{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "#Initializing device details and Importing the dataset\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "(xTrain, yTrain), (xTest, yTest) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xTrain[0]/27, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Preprocessing\n",
    "length, breadth = xTrain[0].shape\n",
    "flattenDim = length * breadth\n",
    "xTrain = torch.FloatTensor(np.round(xTrain / 27).astype(int)).to(device)\n",
    "xTest = np.round(xTest / 27).astype(int)\n",
    "#xTrainFlat = torch.FloatTensor(np.reshape(xTrain, (-1,flattenDim))).to(device)\n",
    "xTestFlat = np.reshape(xTest, (-1,flattenDim)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "trainLoader = DataLoader(dataset = xTrain, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder NN Module consisting of Encoder and Decoder classes\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 3),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(20,9),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "        nn.Linear(9,20),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(in_channels = 64, out_channels = 32, kernel_size = 5),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(in_channels = 32, out_channels = 16, kernel_size = 3),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(in_channels = 16, out_channels = 1, kernel_size = 3),\n",
    "        nn.ReLU(),\n",
    "        nn.Softmax(dim = 1)    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoderOutput = self.Encoder(x)\n",
    "        decoderOutput = self.Decoder(encoderOutput)\n",
    "        return encoderOutput, decoderOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().to(device)\n",
    "modelParameters = list(model.parameters())\n",
    "criterion = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.SGD(modelParameters, lr = (1e-2), momentum=0.5)\n",
    "\n",
    "encoderOutputs = []\n",
    "decoderOutputs = []\n",
    "for epoch in range(100):\n",
    "  losses = []\n",
    "  for batchIndex, batchImage in enumerate(trainLoader):\n",
    "    batchImage = batchImage.to(device)\n",
    "    batchImage = batchImage.unsqueeze(1)\n",
    "    encoderOutput, decoderOutput = model(batchImage)\n",
    "    loss = criterion(decoderOutput, batchImage)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.cpu().detach().numpy())\n",
    "    encoderOutputs.append((epoch, batchIndex, encoderOutput))\n",
    "    decoderOutputs.append((epoch, batchIndex, decoderOutput))\n",
    "  print(\"Epoch: \",epoch,\"| Average loss: \",np.round(np.average(losses), 3),\"| Lowest Loss: \",np.round(np.amin(losses), 3))\n",
    "  torch.save(model.state_dict(), \"AE.pth\")\n",
    " \n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encOutput, decOutput = model(torch.FloatTensor(xTest[100]).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(decOutput.cpu().detach().numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(decoderOutputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dce92b59414b6f3d3d2d8fa4cc50c6a1297a8b6cc151ffcfeb96fc9a7b723860"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
